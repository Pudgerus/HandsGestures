{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, GRU\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "from tensorflow.keras.layers import LayerNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import mediapipe as mp\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('hand_landmarks_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data.drop(columns=['label','label_id', 'path']), data['label_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def super_frame(data, sequence_length = 37, num_features = 63):\n",
    "    raw_data = data.to_numpy()\n",
    "    n_sequences = len(raw_data) // sequence_length\n",
    "    raw_data = raw_data[:n_sequences * sequence_length]\n",
    "    X_seq = raw_data.reshape((n_sequences, sequence_length, num_features))\n",
    "\n",
    "    # \"Суперкадр\" — среднее по последовательности\n",
    "    X_mean = np.mean(X_seq, axis=1, keepdims=True)  # (n_sequences, 1, 63)\n",
    "\n",
    "    # Добавляем к последовательности\n",
    "    X_augmented = np.concatenate([X_seq, X_mean], axis=1)  # (n_sequences, 38, 63)\n",
    "\n",
    "    X = pd.DataFrame(X_augmented.reshape(38*n_sequences, 63))\n",
    "    \n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_X = super_frame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax = MinMaxScaler()\n",
    "X_scaled = minmax.fit_transform(prep_X)\n",
    "\n",
    "window_size_x = 38\n",
    "window_size_y = 37\n",
    "n_samples = len(X_scaled) // window_size_x\n",
    "n_samples_y = len(y) // window_size_y\n",
    "\n",
    "y_seq = np.array(y[:n_samples_y * window_size_y]).reshape(n_samples_y, window_size_y)\n",
    "\n",
    "y_seq = y_seq[:, 0] \n",
    "\n",
    "X_scaled = X_scaled.reshape(n_samples, 38, 63)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_seq, train_size=0.8, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes=27)\n",
    "y_test = to_categorical(y_test, num_classes=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_id\n",
       "0     38184\n",
       "15    16650\n",
       "20    16502\n",
       "16    16243\n",
       "11    16169\n",
       "3     16169\n",
       "26    16095\n",
       "18    16095\n",
       "10    15873\n",
       "8     15873\n",
       "23    15799\n",
       "24    15725\n",
       "6     15725\n",
       "5     15614\n",
       "25    15577\n",
       "19    15577\n",
       "4     15466\n",
       "12    15355\n",
       "9     15318\n",
       "1     15244\n",
       "14    14948\n",
       "2     14763\n",
       "17    14689\n",
       "13    14615\n",
       "7     13986\n",
       "21    11026\n",
       "22    10989\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.08757717, 0.03034138, 0.48643002, ..., 0.14308749,\n",
       "         0.25328326, 0.80484862],\n",
       "        [0.08757717, 0.03034138, 0.48643002, ..., 0.14308749,\n",
       "         0.25328326, 0.80484862],\n",
       "        [0.08757717, 0.03034138, 0.48643002, ..., 0.14308749,\n",
       "         0.25328326, 0.80484862],\n",
       "        ...,\n",
       "        [0.08757717, 0.03034138, 0.48643002, ..., 0.14308749,\n",
       "         0.25328326, 0.80484862],\n",
       "        [0.08757717, 0.03034138, 0.48643002, ..., 0.14308749,\n",
       "         0.25328326, 0.80484862],\n",
       "        [0.08757717, 0.03034138, 0.48643002, ..., 0.14308749,\n",
       "         0.25328326, 0.80484862]],\n",
       "\n",
       "       [[0.52077936, 0.47730463, 0.52501584, ..., 0.559212  ,\n",
       "         0.48411334, 0.79895805],\n",
       "        [0.52071049, 0.4760113 , 0.52500516, ..., 0.5590961 ,\n",
       "         0.47315966, 0.79582027],\n",
       "        [0.08757717, 0.03034138, 0.48643002, ..., 0.14308749,\n",
       "         0.25328326, 0.80484862],\n",
       "        ...,\n",
       "        [0.55241313, 0.50270637, 0.53885878, ..., 0.44449754,\n",
       "         0.46413642, 0.74665566],\n",
       "        [0.55293599, 0.50369351, 0.54200805, ..., 0.44635021,\n",
       "         0.46271068, 0.74407626],\n",
       "        [0.37583313, 0.31812375, 0.51423565, ..., 0.34336755,\n",
       "         0.3965303 , 0.76865678]],\n",
       "\n",
       "       [[0.08757717, 0.03034138, 0.48643002, ..., 0.14308749,\n",
       "         0.25328326, 0.80484862],\n",
       "        [0.08757717, 0.03034138, 0.48643002, ..., 0.14308749,\n",
       "         0.25328326, 0.80484862],\n",
       "        [0.33290638, 0.66008798, 0.5828248 , ..., 0.47009278,\n",
       "         0.87851725, 0.68780709],\n",
       "        ...,\n",
       "        [0.08757717, 0.03034138, 0.48643002, ..., 0.14308749,\n",
       "         0.25328326, 0.80484862],\n",
       "        [0.08757717, 0.03034138, 0.48643002, ..., 0.14308749,\n",
       "         0.25328326, 0.80484862],\n",
       "        [0.2323132 , 0.36268573, 0.53495157, ..., 0.28942279,\n",
       "         0.47549764, 0.75593328]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.08757717, 0.03034138, 0.48643002, ..., 0.14308749,\n",
       "         0.25328326, 0.80484862],\n",
       "        [0.08757717, 0.03034138, 0.48643002, ..., 0.14308749,\n",
       "         0.25328326, 0.80484862],\n",
       "        [0.08757717, 0.03034138, 0.48643002, ..., 0.14308749,\n",
       "         0.25328326, 0.80484862],\n",
       "        ...,\n",
       "        [0.08757717, 0.03034138, 0.48643002, ..., 0.14308749,\n",
       "         0.25328326, 0.80484862],\n",
       "        [0.08757717, 0.03034138, 0.48643002, ..., 0.14308749,\n",
       "         0.25328326, 0.80484862],\n",
       "        [0.18952342, 0.22427793, 0.49956433, ..., 0.2326286 ,\n",
       "         0.39750223, 0.77061015]],\n",
       "\n",
       "       [[0.08757717, 0.03034138, 0.48643002, ..., 0.14308749,\n",
       "         0.25328326, 0.80484862],\n",
       "        [0.08757717, 0.03034138, 0.48643002, ..., 0.14308749,\n",
       "         0.25328326, 0.80484862],\n",
       "        [0.08757717, 0.03034138, 0.48643002, ..., 0.14308749,\n",
       "         0.25328326, 0.80484862],\n",
       "        ...,\n",
       "        [0.08757717, 0.03034138, 0.48643002, ..., 0.14308749,\n",
       "         0.25328326, 0.80484862],\n",
       "        [0.08757717, 0.03034138, 0.48643002, ..., 0.14308749,\n",
       "         0.25328326, 0.80484862],\n",
       "        [0.39297196, 0.37001647, 0.50936764, ..., 0.43160815,\n",
       "         0.43063128, 0.77486576]],\n",
       "\n",
       "       [[0.08757717, 0.03034138, 0.48643002, ..., 0.14308749,\n",
       "         0.25328326, 0.80484862],\n",
       "        [0.08757717, 0.03034138, 0.48643002, ..., 0.14308749,\n",
       "         0.25328326, 0.80484862],\n",
       "        [0.08757717, 0.03034138, 0.48643002, ..., 0.14308749,\n",
       "         0.25328326, 0.80484862],\n",
       "        ...,\n",
       "        [0.08757717, 0.03034138, 0.48643002, ..., 0.14308749,\n",
       "         0.25328326, 0.80484862],\n",
       "        [0.08757717, 0.03034138, 0.48643002, ..., 0.14308749,\n",
       "         0.25328326, 0.80484862],\n",
       "        [0.17375888, 0.1353505 , 0.5006172 , ..., 0.22202519,\n",
       "         0.33420246, 0.78380857]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "294/294 [==============================] - 8s 16ms/step - loss: 3.2703 - accuracy: 0.0800 - precision: 0.0000e+00 - recall: 0.0000e+00 - roc_auc: 0.5537 - pr_auc: 0.0476 - val_loss: 3.2372 - val_accuracy: 0.0865 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_roc_auc: 0.6069 - val_pr_auc: 0.0593\n",
      "Epoch 2/300\n",
      "294/294 [==============================] - 4s 13ms/step - loss: 3.1762 - accuracy: 0.0848 - precision: 0.0000e+00 - recall: 0.0000e+00 - roc_auc: 0.6380 - pr_auc: 0.0617 - val_loss: 3.0996 - val_accuracy: 0.0882 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_roc_auc: 0.6774 - val_pr_auc: 0.0707\n",
      "Epoch 3/300\n",
      "294/294 [==============================] - 4s 13ms/step - loss: 3.0152 - accuracy: 0.1077 - precision: 0.0000e+00 - recall: 0.0000e+00 - roc_auc: 0.7140 - pr_auc: 0.0852 - val_loss: 2.8031 - val_accuracy: 0.1627 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_roc_auc: 0.7798 - val_pr_auc: 0.1224\n",
      "Epoch 4/300\n",
      "294/294 [==============================] - 4s 12ms/step - loss: 2.5699 - accuracy: 0.2186 - precision: 0.7143 - recall: 0.0011 - roc_auc: 0.8284 - pr_auc: 0.1858 - val_loss: 2.3817 - val_accuracy: 0.2892 - val_precision: 0.9032 - val_recall: 0.0119 - val_roc_auc: 0.8569 - val_pr_auc: 0.2547\n",
      "Epoch 5/300\n",
      "294/294 [==============================] - 4s 12ms/step - loss: 2.1512 - accuracy: 0.3453 - precision: 0.7645 - recall: 0.0546 - roc_auc: 0.8882 - pr_auc: 0.3360 - val_loss: 1.9608 - val_accuracy: 0.4008 - val_precision: 0.7944 - val_recall: 0.0971 - val_roc_auc: 0.9086 - val_pr_auc: 0.4094\n",
      "Epoch 6/300\n",
      "294/294 [==============================] - 4s 12ms/step - loss: 1.8920 - accuracy: 0.4275 - precision: 0.7295 - recall: 0.1324 - roc_auc: 0.9144 - pr_auc: 0.4337 - val_loss: 1.7283 - val_accuracy: 0.4808 - val_precision: 0.8091 - val_recall: 0.1823 - val_roc_auc: 0.9300 - val_pr_auc: 0.5117\n",
      "Epoch 7/300\n",
      "294/294 [==============================] - 4s 12ms/step - loss: 1.6789 - accuracy: 0.5088 - precision: 0.7716 - recall: 0.2425 - roc_auc: 0.9311 - pr_auc: 0.5337 - val_loss: 1.6142 - val_accuracy: 0.5119 - val_precision: 0.7987 - val_recall: 0.3024 - val_roc_auc: 0.9368 - val_pr_auc: 0.5589\n",
      "Epoch 8/300\n",
      "294/294 [==============================] - 4s 12ms/step - loss: 1.5350 - accuracy: 0.5518 - precision: 0.7888 - recall: 0.3446 - roc_auc: 0.9404 - pr_auc: 0.5941 - val_loss: 1.3940 - val_accuracy: 0.5775 - val_precision: 0.7949 - val_recall: 0.4110 - val_roc_auc: 0.9511 - val_pr_auc: 0.6435\n",
      "Epoch 9/300\n",
      "294/294 [==============================] - 4s 13ms/step - loss: 1.3883 - accuracy: 0.5980 - precision: 0.8118 - recall: 0.4333 - roc_auc: 0.9499 - pr_auc: 0.6579 - val_loss: 1.2412 - val_accuracy: 0.6414 - val_precision: 0.8362 - val_recall: 0.4979 - val_roc_auc: 0.9590 - val_pr_auc: 0.7101\n",
      "Epoch 10/300\n",
      "294/294 [==============================] - 4s 13ms/step - loss: 1.2875 - accuracy: 0.6280 - precision: 0.8194 - recall: 0.4891 - roc_auc: 0.9562 - pr_auc: 0.6968 - val_loss: 1.2227 - val_accuracy: 0.6482 - val_precision: 0.8306 - val_recall: 0.5200 - val_roc_auc: 0.9612 - val_pr_auc: 0.7163\n",
      "Epoch 11/300\n",
      "294/294 [==============================] - 3s 12ms/step - loss: 1.2112 - accuracy: 0.6544 - precision: 0.8369 - recall: 0.5303 - roc_auc: 0.9602 - pr_auc: 0.7264 - val_loss: 1.1086 - val_accuracy: 0.6831 - val_precision: 0.8469 - val_recall: 0.5724 - val_roc_auc: 0.9644 - val_pr_auc: 0.7645\n",
      "Epoch 12/300\n",
      "294/294 [==============================] - 3s 12ms/step - loss: 1.1226 - accuracy: 0.6820 - precision: 0.8499 - recall: 0.5700 - roc_auc: 0.9646 - pr_auc: 0.7586 - val_loss: 1.1445 - val_accuracy: 0.6767 - val_precision: 0.8438 - val_recall: 0.5754 - val_roc_auc: 0.9612 - val_pr_auc: 0.7541\n",
      "Epoch 13/300\n",
      "294/294 [==============================] - 4s 12ms/step - loss: 1.1015 - accuracy: 0.6818 - precision: 0.8493 - recall: 0.5781 - roc_auc: 0.9663 - pr_auc: 0.7641 - val_loss: 1.0342 - val_accuracy: 0.7006 - val_precision: 0.8519 - val_recall: 0.6052 - val_roc_auc: 0.9708 - val_pr_auc: 0.7856\n",
      "Epoch 14/300\n",
      "294/294 [==============================] - 3s 11ms/step - loss: 1.0288 - accuracy: 0.7074 - precision: 0.8618 - recall: 0.6102 - roc_auc: 0.9697 - pr_auc: 0.7890 - val_loss: 1.0160 - val_accuracy: 0.7117 - val_precision: 0.8515 - val_recall: 0.6299 - val_roc_auc: 0.9692 - val_pr_auc: 0.7939\n",
      "Epoch 15/300\n",
      "294/294 [==============================] - 4s 12ms/step - loss: 1.0015 - accuracy: 0.7154 - precision: 0.8706 - recall: 0.6272 - roc_auc: 0.9711 - pr_auc: 0.7977 - val_loss: 0.9878 - val_accuracy: 0.7172 - val_precision: 0.8603 - val_recall: 0.6320 - val_roc_auc: 0.9709 - val_pr_auc: 0.8036\n",
      "Epoch 16/300\n",
      "294/294 [==============================] - 9s 30ms/step - loss: 0.9890 - accuracy: 0.7179 - precision: 0.8621 - recall: 0.6278 - roc_auc: 0.9715 - pr_auc: 0.8000 - val_loss: 0.9881 - val_accuracy: 0.7206 - val_precision: 0.8599 - val_recall: 0.6405 - val_roc_auc: 0.9696 - val_pr_auc: 0.7996\n",
      "Epoch 17/300\n",
      "294/294 [==============================] - 4s 12ms/step - loss: 0.9533 - accuracy: 0.7313 - precision: 0.8729 - recall: 0.6472 - roc_auc: 0.9733 - pr_auc: 0.8119 - val_loss: 0.9628 - val_accuracy: 0.7287 - val_precision: 0.8670 - val_recall: 0.6525 - val_roc_auc: 0.9698 - val_pr_auc: 0.8132\n",
      "Epoch 18/300\n",
      "294/294 [==============================] - 8s 27ms/step - loss: 0.9216 - accuracy: 0.7394 - precision: 0.8818 - recall: 0.6568 - roc_auc: 0.9749 - pr_auc: 0.8227 - val_loss: 0.9839 - val_accuracy: 0.7279 - val_precision: 0.8456 - val_recall: 0.6461 - val_roc_auc: 0.9693 - val_pr_auc: 0.8080\n",
      "Epoch 19/300\n",
      "294/294 [==============================] - 4s 13ms/step - loss: 0.9053 - accuracy: 0.7435 - precision: 0.8808 - recall: 0.6659 - roc_auc: 0.9762 - pr_auc: 0.8249 - val_loss: 0.9912 - val_accuracy: 0.7159 - val_precision: 0.8566 - val_recall: 0.6359 - val_roc_auc: 0.9707 - val_pr_auc: 0.8018\n",
      "Epoch 20/300\n",
      "294/294 [==============================] - 4s 13ms/step - loss: 0.8695 - accuracy: 0.7558 - precision: 0.8904 - recall: 0.6743 - roc_auc: 0.9779 - pr_auc: 0.8365 - val_loss: 0.9129 - val_accuracy: 0.7415 - val_precision: 0.8676 - val_recall: 0.6780 - val_roc_auc: 0.9734 - val_pr_auc: 0.8282\n",
      "Epoch 21/300\n",
      "294/294 [==============================] - 4s 12ms/step - loss: 0.8540 - accuracy: 0.7574 - precision: 0.8893 - recall: 0.6808 - roc_auc: 0.9782 - pr_auc: 0.8410 - val_loss: 0.9131 - val_accuracy: 0.7470 - val_precision: 0.8782 - val_recall: 0.6755 - val_roc_auc: 0.9732 - val_pr_auc: 0.8272\n",
      "Epoch 22/300\n",
      "294/294 [==============================] - 4s 13ms/step - loss: 0.8332 - accuracy: 0.7645 - precision: 0.8935 - recall: 0.6895 - roc_auc: 0.9789 - pr_auc: 0.8462 - val_loss: 0.9510 - val_accuracy: 0.7338 - val_precision: 0.8598 - val_recall: 0.6661 - val_roc_auc: 0.9710 - val_pr_auc: 0.8173\n",
      "Epoch 23/300\n",
      "294/294 [==============================] - 4s 13ms/step - loss: 0.8423 - accuracy: 0.7591 - precision: 0.8880 - recall: 0.6888 - roc_auc: 0.9788 - pr_auc: 0.8434 - val_loss: 0.9388 - val_accuracy: 0.7347 - val_precision: 0.8562 - val_recall: 0.6695 - val_roc_auc: 0.9726 - val_pr_auc: 0.8175\n",
      "Epoch 24/300\n",
      "294/294 [==============================] - 4s 13ms/step - loss: 0.7951 - accuracy: 0.7725 - precision: 0.8969 - recall: 0.7021 - roc_auc: 0.9810 - pr_auc: 0.8567 - val_loss: 0.9340 - val_accuracy: 0.7372 - val_precision: 0.8565 - val_recall: 0.6738 - val_roc_auc: 0.9709 - val_pr_auc: 0.8186\n",
      "Epoch 25/300\n",
      "294/294 [==============================] - 4s 13ms/step - loss: 0.7940 - accuracy: 0.7723 - precision: 0.8971 - recall: 0.7020 - roc_auc: 0.9813 - pr_auc: 0.8566 - val_loss: 0.9019 - val_accuracy: 0.7479 - val_precision: 0.8633 - val_recall: 0.6861 - val_roc_auc: 0.9731 - val_pr_auc: 0.8321\n",
      "Epoch 26/300\n",
      "294/294 [==============================] - 4s 14ms/step - loss: 0.7780 - accuracy: 0.7764 - precision: 0.9028 - recall: 0.7087 - roc_auc: 0.9817 - pr_auc: 0.8617 - val_loss: 0.9206 - val_accuracy: 0.7509 - val_precision: 0.8590 - val_recall: 0.6925 - val_roc_auc: 0.9709 - val_pr_auc: 0.8300\n",
      "Epoch 27/300\n",
      "294/294 [==============================] - 4s 14ms/step - loss: 0.7547 - accuracy: 0.7833 - precision: 0.9043 - recall: 0.7198 - roc_auc: 0.9825 - pr_auc: 0.8676 - val_loss: 0.8981 - val_accuracy: 0.7496 - val_precision: 0.8681 - val_recall: 0.6895 - val_roc_auc: 0.9736 - val_pr_auc: 0.8326\n",
      "Epoch 28/300\n",
      "294/294 [==============================] - 4s 14ms/step - loss: 0.7613 - accuracy: 0.7824 - precision: 0.9043 - recall: 0.7165 - roc_auc: 0.9827 - pr_auc: 0.8655 - val_loss: 0.9611 - val_accuracy: 0.7321 - val_precision: 0.8503 - val_recall: 0.6750 - val_roc_auc: 0.9699 - val_pr_auc: 0.8173\n",
      "Epoch 29/300\n",
      "294/294 [==============================] - 4s 13ms/step - loss: 0.7484 - accuracy: 0.7872 - precision: 0.9069 - recall: 0.7214 - roc_auc: 0.9831 - pr_auc: 0.8695 - val_loss: 0.9170 - val_accuracy: 0.7419 - val_precision: 0.8566 - val_recall: 0.6793 - val_roc_auc: 0.9739 - val_pr_auc: 0.8236\n",
      "Epoch 30/300\n",
      "294/294 [==============================] - 4s 14ms/step - loss: 0.7267 - accuracy: 0.7934 - precision: 0.9130 - recall: 0.7277 - roc_auc: 0.9842 - pr_auc: 0.8757 - val_loss: 0.9228 - val_accuracy: 0.7509 - val_precision: 0.8639 - val_recall: 0.6951 - val_roc_auc: 0.9704 - val_pr_auc: 0.8307\n",
      "Epoch 31/300\n",
      "294/294 [==============================] - 4s 13ms/step - loss: 0.7112 - accuracy: 0.7952 - precision: 0.9144 - recall: 0.7329 - roc_auc: 0.9850 - pr_auc: 0.8789 - val_loss: 0.9103 - val_accuracy: 0.7479 - val_precision: 0.8584 - val_recall: 0.6865 - val_roc_auc: 0.9716 - val_pr_auc: 0.8341\n",
      "Epoch 32/300\n",
      "294/294 [==============================] - 4s 13ms/step - loss: 0.7009 - accuracy: 0.7997 - precision: 0.9127 - recall: 0.7376 - roc_auc: 0.9850 - pr_auc: 0.8830 - val_loss: 0.9562 - val_accuracy: 0.7389 - val_precision: 0.8483 - val_recall: 0.6908 - val_roc_auc: 0.9697 - val_pr_auc: 0.8225\n",
      "Epoch 33/300\n",
      "294/294 [==============================] - 4s 13ms/step - loss: 0.6979 - accuracy: 0.8010 - precision: 0.9149 - recall: 0.7399 - roc_auc: 0.9847 - pr_auc: 0.8823 - val_loss: 0.9126 - val_accuracy: 0.7419 - val_precision: 0.8566 - val_recall: 0.6844 - val_roc_auc: 0.9731 - val_pr_auc: 0.8300\n",
      "Epoch 34/300\n",
      "294/294 [==============================] - 4s 13ms/step - loss: 0.6895 - accuracy: 0.8043 - precision: 0.9152 - recall: 0.7394 - roc_auc: 0.9855 - pr_auc: 0.8851 - val_loss: 0.8997 - val_accuracy: 0.7509 - val_precision: 0.8641 - val_recall: 0.6989 - val_roc_auc: 0.9712 - val_pr_auc: 0.8355\n",
      "Epoch 35/300\n",
      "294/294 [==============================] - 4s 14ms/step - loss: 0.6641 - accuracy: 0.8100 - precision: 0.9222 - recall: 0.7507 - roc_auc: 0.9865 - pr_auc: 0.8913 - val_loss: 0.9225 - val_accuracy: 0.7449 - val_precision: 0.8544 - val_recall: 0.6921 - val_roc_auc: 0.9707 - val_pr_auc: 0.8283\n",
      "Epoch 36/300\n",
      "294/294 [==============================] - 4s 13ms/step - loss: 0.6815 - accuracy: 0.8015 - precision: 0.9142 - recall: 0.7441 - roc_auc: 0.9857 - pr_auc: 0.8867 - val_loss: 0.9226 - val_accuracy: 0.7543 - val_precision: 0.8613 - val_recall: 0.7006 - val_roc_auc: 0.9687 - val_pr_auc: 0.8309\n",
      "Epoch 37/300\n",
      "294/294 [==============================] - 4s 13ms/step - loss: 0.6369 - accuracy: 0.8170 - precision: 0.9263 - recall: 0.7621 - roc_auc: 0.9871 - pr_auc: 0.8980 - val_loss: 0.8961 - val_accuracy: 0.7551 - val_precision: 0.8565 - val_recall: 0.7019 - val_roc_auc: 0.9711 - val_pr_auc: 0.8392\n",
      "Epoch 38/300\n",
      "294/294 [==============================] - 4s 13ms/step - loss: 0.6404 - accuracy: 0.8180 - precision: 0.9250 - recall: 0.7611 - roc_auc: 0.9867 - pr_auc: 0.8975 - val_loss: 0.9484 - val_accuracy: 0.7500 - val_precision: 0.8524 - val_recall: 0.6938 - val_roc_auc: 0.9680 - val_pr_auc: 0.8276\n",
      "Epoch 39/300\n",
      "294/294 [==============================] - 4s 12ms/step - loss: 0.6417 - accuracy: 0.8163 - precision: 0.9236 - recall: 0.7592 - roc_auc: 0.9868 - pr_auc: 0.8970 - val_loss: 0.9455 - val_accuracy: 0.7491 - val_precision: 0.8507 - val_recall: 0.6989 - val_roc_auc: 0.9692 - val_pr_auc: 0.8280\n",
      "Epoch 40/300\n",
      "294/294 [==============================] - 4s 12ms/step - loss: 0.6635 - accuracy: 0.8094 - precision: 0.9179 - recall: 0.7499 - roc_auc: 0.9869 - pr_auc: 0.8908 - val_loss: 0.9216 - val_accuracy: 0.7517 - val_precision: 0.8565 - val_recall: 0.7019 - val_roc_auc: 0.9692 - val_pr_auc: 0.8315\n",
      "Epoch 41/300\n",
      "294/294 [==============================] - 4s 12ms/step - loss: 0.6071 - accuracy: 0.8252 - precision: 0.9305 - recall: 0.7702 - roc_auc: 0.9884 - pr_auc: 0.9057 - val_loss: 0.9359 - val_accuracy: 0.7606 - val_precision: 0.8677 - val_recall: 0.7125 - val_roc_auc: 0.9659 - val_pr_auc: 0.8316\n",
      "Epoch 42/300\n",
      "294/294 [==============================] - 4s 12ms/step - loss: 0.6474 - accuracy: 0.8170 - precision: 0.9237 - recall: 0.7603 - roc_auc: 0.9865 - pr_auc: 0.8950 - val_loss: 0.9187 - val_accuracy: 0.7555 - val_precision: 0.8549 - val_recall: 0.7074 - val_roc_auc: 0.9689 - val_pr_auc: 0.8346\n",
      "Epoch 43/300\n",
      "294/294 [==============================] - 3s 11ms/step - loss: 0.5895 - accuracy: 0.8307 - precision: 0.9332 - recall: 0.7754 - roc_auc: 0.9894 - pr_auc: 0.9108 - val_loss: 0.9226 - val_accuracy: 0.7615 - val_precision: 0.8565 - val_recall: 0.7091 - val_roc_auc: 0.9702 - val_pr_auc: 0.8380\n",
      "Epoch 44/300\n",
      "294/294 [==============================] - 3s 12ms/step - loss: 0.6153 - accuracy: 0.8232 - precision: 0.9278 - recall: 0.7708 - roc_auc: 0.9884 - pr_auc: 0.9032 - val_loss: 0.9021 - val_accuracy: 0.7589 - val_precision: 0.8625 - val_recall: 0.7108 - val_roc_auc: 0.9703 - val_pr_auc: 0.8407\n",
      "Epoch 45/300\n",
      "294/294 [==============================] - 3s 11ms/step - loss: 0.6198 - accuracy: 0.8215 - precision: 0.9253 - recall: 0.7691 - roc_auc: 0.9883 - pr_auc: 0.9023 - val_loss: 0.9961 - val_accuracy: 0.7466 - val_precision: 0.8326 - val_recall: 0.6989 - val_roc_auc: 0.9635 - val_pr_auc: 0.8245\n",
      "Epoch 46/300\n",
      "294/294 [==============================] - 3s 12ms/step - loss: 0.5955 - accuracy: 0.8294 - precision: 0.9327 - recall: 0.7791 - roc_auc: 0.9886 - pr_auc: 0.9088 - val_loss: 0.9305 - val_accuracy: 0.7658 - val_precision: 0.8606 - val_recall: 0.7176 - val_roc_auc: 0.9664 - val_pr_auc: 0.8404\n",
      "Epoch 47/300\n",
      "294/294 [==============================] - 4s 12ms/step - loss: 0.5867 - accuracy: 0.8318 - precision: 0.9336 - recall: 0.7807 - roc_auc: 0.9887 - pr_auc: 0.9109 - val_loss: 0.9338 - val_accuracy: 0.7577 - val_precision: 0.8599 - val_recall: 0.7057 - val_roc_auc: 0.9674 - val_pr_auc: 0.8341\n",
      "Epoch 48/300\n",
      "294/294 [==============================] - 3s 11ms/step - loss: 0.5753 - accuracy: 0.8358 - precision: 0.9361 - recall: 0.7854 - roc_auc: 0.9893 - pr_auc: 0.9129 - val_loss: 0.9874 - val_accuracy: 0.7543 - val_precision: 0.8512 - val_recall: 0.7091 - val_roc_auc: 0.9626 - val_pr_auc: 0.8288\n",
      "Epoch 49/300\n",
      "294/294 [==============================] - 3s 11ms/step - loss: 0.5622 - accuracy: 0.8377 - precision: 0.9408 - recall: 0.7868 - roc_auc: 0.9901 - pr_auc: 0.9162 - val_loss: 0.9796 - val_accuracy: 0.7564 - val_precision: 0.8563 - val_recall: 0.7104 - val_roc_auc: 0.9626 - val_pr_auc: 0.8233\n",
      "Epoch 50/300\n",
      "294/294 [==============================] - 4s 12ms/step - loss: 0.5906 - accuracy: 0.8276 - precision: 0.9299 - recall: 0.7784 - roc_auc: 0.9895 - pr_auc: 0.9093 - val_loss: 1.0497 - val_accuracy: 0.7355 - val_precision: 0.8299 - val_recall: 0.6878 - val_roc_auc: 0.9601 - val_pr_auc: 0.8104\n",
      "Epoch 51/300\n",
      "294/294 [==============================] - 3s 12ms/step - loss: 0.5668 - accuracy: 0.8367 - precision: 0.9373 - recall: 0.7867 - roc_auc: 0.9894 - pr_auc: 0.9158 - val_loss: 0.9731 - val_accuracy: 0.7572 - val_precision: 0.8602 - val_recall: 0.7074 - val_roc_auc: 0.9648 - val_pr_auc: 0.8270\n",
      "Epoch 52/300\n",
      "294/294 [==============================] - 3s 12ms/step - loss: 0.5616 - accuracy: 0.8373 - precision: 0.9423 - recall: 0.7880 - roc_auc: 0.9904 - pr_auc: 0.9159 - val_loss: 0.9488 - val_accuracy: 0.7594 - val_precision: 0.8590 - val_recall: 0.7138 - val_roc_auc: 0.9660 - val_pr_auc: 0.8359\n",
      "Epoch 53/300\n",
      "294/294 [==============================] - 3s 12ms/step - loss: 0.5655 - accuracy: 0.8353 - precision: 0.9377 - recall: 0.7903 - roc_auc: 0.9898 - pr_auc: 0.9149 - val_loss: 0.9428 - val_accuracy: 0.7606 - val_precision: 0.8594 - val_recall: 0.7134 - val_roc_auc: 0.9685 - val_pr_auc: 0.8364\n",
      "Epoch 54/300\n",
      "294/294 [==============================] - 3s 12ms/step - loss: 0.5447 - accuracy: 0.8443 - precision: 0.9446 - recall: 0.7972 - roc_auc: 0.9906 - pr_auc: 0.9203 - val_loss: 0.9507 - val_accuracy: 0.7602 - val_precision: 0.8539 - val_recall: 0.7147 - val_roc_auc: 0.9659 - val_pr_auc: 0.8391\n",
      "Epoch 55/300\n",
      "294/294 [==============================] - 3s 12ms/step - loss: 0.5335 - accuracy: 0.8436 - precision: 0.9441 - recall: 0.7971 - roc_auc: 0.9909 - pr_auc: 0.9230 - val_loss: 0.9633 - val_accuracy: 0.7594 - val_precision: 0.8543 - val_recall: 0.7193 - val_roc_auc: 0.9643 - val_pr_auc: 0.8358\n",
      "Epoch 56/300\n",
      "294/294 [==============================] - 3s 12ms/step - loss: 0.5241 - accuracy: 0.8512 - precision: 0.9497 - recall: 0.8025 - roc_auc: 0.9911 - pr_auc: 0.9250 - val_loss: 0.9960 - val_accuracy: 0.7551 - val_precision: 0.8522 - val_recall: 0.7121 - val_roc_auc: 0.9643 - val_pr_auc: 0.8309\n",
      "Epoch 57/300\n",
      "294/294 [==============================] - 3s 11ms/step - loss: 0.5644 - accuracy: 0.8370 - precision: 0.9383 - recall: 0.7886 - roc_auc: 0.9899 - pr_auc: 0.9155 - val_loss: 1.0147 - val_accuracy: 0.7521 - val_precision: 0.8472 - val_recall: 0.7061 - val_roc_auc: 0.9627 - val_pr_auc: 0.8248\n",
      "74/74 - 2s - loss: 0.8961 - accuracy: 0.7551 - precision: 0.8565 - recall: 0.7019 - roc_auc: 0.9711 - pr_auc: 0.8392 - 2s/epoch - 30ms/step\n",
      "Loss: 0.8961025476455688\n",
      "Accuracy: 0.7551107406616211\n",
      "Precision: 0.8565488457679749\n",
      "Recall: 0.7018739581108093\n",
      "ROC AUC: 0.9711291193962097\n",
      "PR AUC: 0.8391633033752441\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0\n",
    "best_model = 0\n",
    "\n",
    "# Генерация всех комбинац\n",
    "\n",
    "# Перебор комбинаций\n",
    "\n",
    "model = Sequential([\n",
    "    Bidirectional(GRU(64, return_sequences=True, input_shape=(37, 63))),\n",
    "    LayerNormalization(),\n",
    "    GRU(64),\n",
    "    Dropout(0.3),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(27, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        Precision(name='precision'),\n",
    "        Recall(name='recall'),\n",
    "        AUC(name='roc_auc', curve='ROC'),\n",
    "        AUC(name='pr_auc', curve='PR')  # <-- добавь PR AUC сюда\n",
    "    ]\n",
    ")\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=20,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "callbacks = [early_stop]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=300,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "results = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(\"Loss:\", results[0])\n",
    "print(\"Accuracy:\", results[1])\n",
    "print(\"Precision:\", results[2])\n",
    "print(\"Recall:\", results[3])\n",
    "print(\"ROC AUC:\", results[4])\n",
    "print(\"PR AUC:\", results[5])\n",
    "\n",
    "model.save(\"best_model.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = 0\n",
    "best_model = 0\n",
    "\n",
    "# Генерация всех комбинац\n",
    "\n",
    "# Перебор комбинаций\n",
    "\n",
    "model = Sequential([\n",
    "    Bidirectional(GRU(64, return_sequences=True, input_shape=(37, 63))),\n",
    "    LayerNormalization(),\n",
    "    GRU(64),\n",
    "    Dropout(0.3),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(27, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        Precision(name='precision'),\n",
    "        Recall(name='recall'),\n",
    "        AUC(name='roc_auc', curve='ROC'),\n",
    "        AUC(name='pr_auc', curve='PR')  # <-- добавь PR AUC сюда\n",
    "    ]\n",
    ")\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=20,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "callbacks = [early_stop]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=300,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "results = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(\"Loss:\", results[0])\n",
    "print(\"Accuracy:\", results[1])\n",
    "print(\"Precision:\", results[2])\n",
    "print(\"Recall:\", results[3])\n",
    "print(\"ROC AUC:\", results[4])\n",
    "print(\"PR AUC:\", results[5])\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
